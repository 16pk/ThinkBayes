{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A Hierarchical Model {#hierarchical}\n",
    "====================\n",
    "\n",
    "The Geiger counter problem\n",
    "--------------------------\n",
    "\n",
    "I got the idea for the following problem from Tom Campbell-Ricketts,\n",
    "author of the Maximum Entropy blog at\n",
    "<http://maximum-entropy-blog.blogspot.com>. And he got the idea from\n",
    "E. T. Jaynes, author of the classic <span>*Probability Theory: The Logic\n",
    "of Science*</span>:\n",
    "\n",
    "> Suppose that a radioactive source emits particles toward a Geiger\n",
    "> counter at an average rate of $r$ particles per second, but the\n",
    "> counter only registers a fraction, $f$, of the particles that hit it.\n",
    "> If $f$ is 10% and the counter registers 15 particles in a one second\n",
    "> interval, what is the posterior distribution of $n$, the actual number\n",
    "> of particles that hit the counter, and $r$, the average rate particles\n",
    "> are emitted?\n",
    "\n",
    "To get started on a problem like this, think about the chain of\n",
    "causation that starts with the parameters of the system and ends with\n",
    "the observed data:\n",
    "\n",
    "1.  The source emits particles at an average rate, $r$.\n",
    "\n",
    "2.  During any given second, the source emits $n$ particles toward the\n",
    "    counter.\n",
    "\n",
    "3.  Out of those $n$ particles, some number, $k$, get counted.\n",
    "\n",
    "The probability that an atom decays is the same at any point in time, so\n",
    "radioactive decay is well modeled by a Poisson process. Given $r$, the\n",
    "distribution of $n$ is Poisson distribution with parameter $r$.\n",
    "\n",
    "And if we assume that the probability of detection for each particle is\n",
    "independent of the others, the distribution of $k$ is the binomial\n",
    "distribution with parameters $n$ and $f$.\n",
    "\n",
    "Given the parameters of the system, we can find the distribution of the\n",
    "data. So we can solve what is called the <span>**forward\n",
    "problem**</span>.\n",
    "\n",
    "Now we want to go the other way: given the data, we want the\n",
    "distribution of the parameters. This is called the <span>**inverse\n",
    "problem**</span>. And if you can solve the forward problem, you can use\n",
    "Bayesian methods to solve the inverse problem.\n",
    "\n",
    "Start simple\n",
    "------------\n",
    "\n",
    "![Posterior distribution of $n$ for three values of\n",
    "$r$.](figs/jaynes1.pdf)\n",
    "\n",
    "[fig.jaynes1]\n",
    "\n",
    "Let’s start with a simple version of the problem where we know the value\n",
    "of $r$. We are given the value of $f$, so all we have to do is estimate\n",
    "$n$.\n",
    "\n",
    "I define a Suite called <span>Detector</span> that models the behavior\n",
    "of the detector and estimates $n$.\n",
    "\n",
    "    class Detector(thinkbayes.Suite):\n",
    "\n",
    "        def __init__(self, r, f, high=500, step=1):\n",
    "            pmf = thinkbayes.MakePoissonPmf(r, high, step=step)\n",
    "            thinkbayes.Suite.__init__(self, pmf, name=r)\n",
    "            self.r = r\n",
    "            self.f = f\n",
    "\n",
    "If the average emission rate is $r$ particles per second, the\n",
    "distribution of $n$ is Poisson with parameter $r$. <span>high</span> and\n",
    "<span>step</span> determine the upper bound for $n$ and the step size\n",
    "between hypothetical values.\n",
    "\n",
    "Now we need a likelihood function:\n",
    "\n",
    "    # class Detector\n",
    "\n",
    "        def Likelihood(self, data, hypo):\n",
    "            k = data\n",
    "            n = hypo\n",
    "            p = self.f\n",
    "\n",
    "            return thinkbayes.EvalBinomialPmf(k, n, p)\n",
    "\n",
    "<span>data</span> is the number of particles detected, and\n",
    "<span>hypo</span> is the hypothetical number of particles emitted, $n$.\n",
    "\n",
    "If there are actually $n$ particles, and the probability of detecting\n",
    "any one of them is $f$, the probability of detecting $k$ particles is\n",
    "given by the binomial distribution.\n",
    "\n",
    "That’s it for the Detector. We can try it out for a range of values of\n",
    "$r$:\n",
    "\n",
    "        f = 0.1\n",
    "        k = 15\n",
    "\n",
    "        for r in [100, 250, 400]:\n",
    "            suite = Detector(r, f, step=1)\n",
    "            suite.Update(k)\n",
    "            print suite.MaximumLikelihood()\n",
    "\n",
    "Figure [fig.jaynes1] shows the posterior distribution of $n$ for several\n",
    "given values of $r$.\n",
    "\n",
    "Make it hierarchical\n",
    "--------------------\n",
    "\n",
    "In the previous section, we assume $r$ is known. Now let’s relax that\n",
    "assumption. I define another Suite, called <span>Emitter</span>, that\n",
    "models the behavior of the emitter and estimates $r$:\n",
    "\n",
    "    class Emitter(thinkbayes.Suite):\n",
    "\n",
    "        def __init__(self, rs, f=0.1):\n",
    "            detectors = [Detector(r, f) for r in rs]\n",
    "            thinkbayes.Suite.__init__(self, detectors)\n",
    "\n",
    "<span>rs</span> is a sequence of hypothetical value for $r$.\n",
    "<span>detectors</span> is a sequence of Detector objects, one for each\n",
    "value of $r$. The values in the Suite are Detectors, so Emitter is a\n",
    "<span>**meta-Suite**</span>; that is, a Suite that contains other Suites\n",
    "as values.\n",
    "\n",
    "To update the Emitter, we have to compute the likelihood of the data\n",
    "under each hypothetical value of $r$. But each value of $r$ is\n",
    "represented by a Detector that contains a range of values for $n$.\n",
    "\n",
    "To compute the likelihood of the data for a given Detector, we loop\n",
    "through the values of $n$ and add up the total probability of $k$.\n",
    "That’s what <span>SuiteLikelihood</span> does:\n",
    "\n",
    "    # class Detector\n",
    "\n",
    "        def SuiteLikelihood(self, data):\n",
    "            total = 0\n",
    "            for hypo, prob in self.Items():\n",
    "                like = self.Likelihood(data, hypo)\n",
    "                total += prob * like\n",
    "            return total\n",
    "\n",
    "Now we can write the Likelihood function for the Emitter:\n",
    "\n",
    "    # class Detector\n",
    "\n",
    "        def Likelihood(self, data, hypo):\n",
    "            detector = hypo\n",
    "            like = detector.SuiteLikelihood(data)\n",
    "            return like\n",
    "\n",
    "Each <span>hypo</span> is a Detector, so we can invoke\n",
    "<span>SuiteLikelihood</span> to get the likelihood of the data under the\n",
    "hypothesis.\n",
    "\n",
    "After we update the Emitter, we have to update each of the Detectors,\n",
    "too.\n",
    "\n",
    "    # class Detector\n",
    "\n",
    "        def Update(self, data):\n",
    "            thinkbayes.Suite.Update(self, data)\n",
    "            \n",
    "            for detector in self.Values():\n",
    "                detector.Update()\n",
    "\n",
    "A model like this, with multiple levels of Suites, is called\n",
    "<span>**hierarchical**</span>.\n",
    "\n",
    "A little optimization\n",
    "---------------------\n",
    "\n",
    "You might recognize <span>SuiteLikelihood</span>; we saw it in\n",
    "Section [suitelike]. At the time, I pointed out that we didn’t really\n",
    "need it, because the total probability computed by\n",
    "<span>SuiteLikelihood</span> is exactly the normalizing constant\n",
    "computed and returned by <span>Update</span>.\n",
    "\n",
    "So instead of updating the Emitter and then updating the Detectors, we\n",
    "can do both steps at the same time, using the result from\n",
    "<span>Detector.Update</span> as the likelihood of Emitter.\n",
    "\n",
    "Here’s the streamlined version of <span>Emitter.Likelihood</span>:\n",
    "\n",
    "    # class Emitter\n",
    "\n",
    "        def Likelihood(self, data, hypo):\n",
    "            return hypo.Update(data)\n",
    "\n",
    "And with this version of <span>Likelihood</span> we can use the default\n",
    "version of <span>Update</span>. So this version has fewer lines of code,\n",
    "and it runs faster because it does not compute the normalizing constant\n",
    "twice.\n",
    "\n",
    "Extracting the posteriors\n",
    "-------------------------\n",
    "\n",
    "![Posterior distributions of $n$ and $r$.](figs/jaynes2.pdf)\n",
    "\n",
    "[fig.jaynes2]\n",
    "\n",
    "After we update the Emitter, we can get the posterior distribution of\n",
    "$r$ by looping through the Detectors and their probabilities:\n",
    "\n",
    "    # class Emitter\n",
    "\n",
    "        def DistOfR(self):\n",
    "            items = [(detector.r, prob) for detector, prob in self.Items()]\n",
    "            return thinkbayes.MakePmfFromItems(items)\n",
    "\n",
    "<span>items</span> is a list of values of $r$ and their probabilities.\n",
    "The result is the Pmf of $r$.\n",
    "\n",
    "To get the posterior distribution of $n$, we have to compute the mixture\n",
    "of the Detectors. We can use <span>thinkbayes.MakeMixture</span>, which\n",
    "takes a meta-Pmf that maps from each distribution to its probability.\n",
    "And that’s exactly what the Emitter is:\n",
    "\n",
    "    # class Emitter\n",
    "\n",
    "        def DistOfN(self):\n",
    "            return thinkbayes.MakeMixture(self)\n",
    "\n",
    "Figure [fig.jaynes2] shows the results. Not surprisingly, the most\n",
    "likely value for $n$ is 150. Given $f$ and $n$, the expected count is\n",
    "$k = f n$, so given $f$ and $k$, the expected value of $n$ is $k / f$,\n",
    "which is 150.\n",
    "\n",
    "And if 150 particles are emitted in one second, the most likely value of\n",
    "$r$ is 150 particles per second. So the posterior distribution of $r$ is\n",
    "also centered on 150.\n",
    "\n",
    "The posterior distributions of $r$ and $n$ are similar; the only\n",
    "difference is that we are slightly less certain about $n$. In general,\n",
    "we can be more certain about the long-range emission rate, $r$, than\n",
    "about the number of particles emitted in any particular second, $n$.\n",
    "\n",
    "You can download the code in this chapter from\n",
    "<http://thinkbayes.com/jaynes.py>. For more information see\n",
    "Section [download].\n",
    "\n",
    "Discussion\n",
    "----------\n",
    "\n",
    "The Geiger counter problem demonstrates the connection between causation\n",
    "and hierarchical modeling. In the example, the emission rate $r$ has a\n",
    "causal effect on the number of particles, $n$, which has a causal effect\n",
    "on the particle count, $k$.\n",
    "\n",
    "The hierarchical model reflects the structure of the system, with causes\n",
    "at the top and effects at the bottom.\n",
    "\n",
    "1.  At the top level, we start with a range of hypothetical values for\n",
    "    $r$.\n",
    "\n",
    "2.  For each value of $r$, we have a range of values for $n$, and the\n",
    "    prior distribution of $n$ depends on $r$.\n",
    "\n",
    "3.  When we update the model, we go bottom-up. We compute a posterior\n",
    "    distribution of $n$ for each value of $r$, then compute the\n",
    "    posterior distribution of $r$.\n",
    "\n",
    "So causal information flows down the hierarchy, and inference flows up.\n",
    "\n",
    "Exercises\n",
    "---------\n",
    "\n",
    "This exercise is also inspired by an example in Jaynes,\n",
    "<span>*Probability Theory*</span>.\n",
    "\n",
    "Suppose you buy a mosquito trap that is supposed to reduce the\n",
    "population of mosquitoes near your house. Each week, you empty the trap\n",
    "and count the number of mosquitoes captured. After the first week, you\n",
    "count 30 mosquitoes. After the second week, you count 20 mosquitoes.\n",
    "Estimate the percentage change in the number of mosquitoes in your yard.\n",
    "\n",
    "To answer this question, you have to make some modeling decisions. Here\n",
    "are some suggestions:\n",
    "\n",
    "-   Suppose that each week a large number of mosquitoes, $N$, is bred in\n",
    "    a wetland near your home.\n",
    "\n",
    "-   During the week, some fraction of them, $f_1$, wander into your\n",
    "    yard, and of those some fraction, $f_2$, are caught in the trap.\n",
    "\n",
    "-   Your solution should take into account your prior belief about how\n",
    "    much $N$ is likely to change from one week to the next. You can do\n",
    "    that by adding a level to the hierarchy to model the percent change\n",
    "    in $N$.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
