{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Prediction\n",
    "==========\n",
    "\n",
    "The Boston Bruins problem\n",
    "-------------------------\n",
    "\n",
    "In the 2010-11 National Hockey League (NHL) Finals, my beloved Boston\n",
    "Bruins played a best-of-seven championship series against the despised\n",
    "Vancouver Canucks. Boston lost the first two games 0-1 and 2-3, then won\n",
    "the next two games 8-1 and 4-0. At this point in the series, what is the\n",
    "probability that Boston will win the next game, and what is their\n",
    "probability of winning the championship?\n",
    "\n",
    "As always, to answer a question like this, we need to make some\n",
    "assumptions. First, it is reasonable to believe that goal scoring in\n",
    "hockey is at least approximately a Poisson process, which means that it\n",
    "is equally likely for a goal to be scored at any time during a game.\n",
    "Second, we can assume that against a particular opponent, each team has\n",
    "some long-term average goals per game, denoted $\\lambda$.\n",
    "\n",
    "Given these assumptions, my strategy for answering this question is\n",
    "\n",
    "1.  Use statistics from previous games to choose a prior distribution\n",
    "    for $\\lambda$.\n",
    "\n",
    "2.  Use the score from the first four games to estimate $\\lambda$ for\n",
    "    each team.\n",
    "\n",
    "3.  Use the posterior distributions of $\\lambda$ to compute distribution\n",
    "    of goals for each team, the distribution of the goal differential,\n",
    "    and the probability that each team wins the next game.\n",
    "\n",
    "4.  Compute the probability that each team wins the series.\n",
    "\n",
    "To choose a prior distribution, I got some statistics from\n",
    "<http://www.nhl.com>, specifically the average goals per game for each\n",
    "team in the 2010-11 season. The distribution is roughly Gaussian with\n",
    "mean 2.8 and standard deviation 0.3.\n",
    "\n",
    "The Gaussian distribution is continuous, but we’ll approximate it with a\n",
    "discrete Pmf. `thinkbayes` provides `MakeGaussianPmf` to do exactly\n",
    "that:\n",
    "\n",
    "    def MakeGaussianPmf(mu, sigma, num_sigmas, n=101):\n",
    "        pmf = Pmf()\n",
    "        low = mu - num_sigmas*sigma\n",
    "        high = mu + num_sigmas*sigma\n",
    "\n",
    "        for x in numpy.linspace(low, high, n):\n",
    "            p = scipy.stats.norm.pdf(mu, sigma, x)\n",
    "            pmf.Set(x, p)\n",
    "        pmf.Normalize()\n",
    "        return pmf\n",
    "\n",
    "<span>mu</span> and <span>sigma</span> are the mean and standard\n",
    "deviation of the Gaussian distribution. `num_sigmas` is the number of\n",
    "standard deviations above and below the mean that the Pmf will span, and\n",
    "<span>n</span> is the number of values in the Pmf.\n",
    "\n",
    "Again we use <span>numpy.linspace</span> to make an array of\n",
    "<span>n</span> equally spaced values between <span>low</span> and\n",
    "<span>high</span>, including both.\n",
    "\n",
    "`norm.pdf` evaluates the Gaussian probability density function (PDF).\n",
    "\n",
    "Getting back to the hockey problem, here’s the definition for a suite of\n",
    "hypotheses about the value of $\\lambda$.\n",
    "\n",
    "    class Hockey(thinkbayes.Suite):\n",
    "\n",
    "        def __init__(self):\n",
    "            pmf = thinkbayes.MakeGaussianPmf(2.7, 0.3, 4)\n",
    "            thinkbayes.Suite.__init__(self, pmf)\n",
    "\n",
    "So the prior distribution is Gaussian with mean 2.7, standard deviation\n",
    "0.3, and it spans 4 sigmas above and below the mean.\n",
    "\n",
    "As always, we have to decide how to represent each hypothesis; in this\n",
    "case I represent the hypothesis that $\\lambda=x$ with the floating-point\n",
    "value <span>x</span>.\n",
    "\n",
    "Poisson processes\n",
    "-----------------\n",
    "\n",
    "In mathematical statistics, a <span>**process**</span> is a stochastic\n",
    "model of a physical system (“stochastic” means that the model has some\n",
    "kind of randomness in it). For example, a Bernoulli process is a model\n",
    "of a sequence of events, called trials, in which each trial has two\n",
    "possible outcomes, like success and failure. So a Bernoulli process is a\n",
    "natural model for a series of coin flips, or a series of shots on goal.\n",
    "\n",
    "A Poisson process is the continuous version of a Bernoulli process,\n",
    "where an event can occur at any point in time with equal probability.\n",
    "Poisson processes can be used to model customers arriving in a store,\n",
    "buses arriving at a bus stop, or goals scored in a hockey game.\n",
    "\n",
    "In many real systems the probability of an event changes over time.\n",
    "Customers are more likely to go to a store at certain times of day,\n",
    "buses are supposed to arrive at fixed intervals, and goals are more or\n",
    "less likely at different times during a game.\n",
    "\n",
    "But all models are based on simplifications, and in this case modeling a\n",
    "hockey game with a Poisson process is a reasonable choice. Heuer, Müller\n",
    "and Rubner (2010) analyze scoring in a German soccer league and come to\n",
    "the same conclusion; see\n",
    "<http://www.cimat.mx/Eventos/vpec10/img/poisson.pdf>.\n",
    "\n",
    "The benefit of using this model is that we can compute the distribution\n",
    "of goals per game efficiently, as well as the distribution of time\n",
    "between goals. Specifically, if the average number of goals in a game is\n",
    "<span>lam</span>, the distribution of goals per game is given by the\n",
    "Poisson PMF:\n",
    "\n",
    "    def EvalPoissonPmf(k, lam):\n",
    "        return (lam)**k * math.exp(-lam) / math.factorial(k)\n",
    "\n",
    "And the distribution of time between goals is given by the exponential\n",
    "PDF:\n",
    "\n",
    "    def EvalExponentialPdf(x, lam):\n",
    "        return lam * math.exp(-lam * x)\n",
    "\n",
    "I use the variable <span>lam</span> because <span>lambda</span> is a\n",
    "reserved keyword in Python. Both of these functions are in\n",
    "`thinkbayes.py`.\n",
    "\n",
    "The posteriors\n",
    "--------------\n",
    "\n",
    "![Posterior distribution of the number of goals per\n",
    "game.](figs/hockey1.pdf)\n",
    "\n",
    "[fig.hockey1]\n",
    "\n",
    "Now we can compute the likelihood that a team with a hypothetical value\n",
    "of <span>lam</span> scores <span>k</span> goals in a game:\n",
    "\n",
    "    # class Hockey\n",
    "\n",
    "        def Likelihood(self, data, hypo):\n",
    "            lam = hypo\n",
    "            k = data\n",
    "            like = thinkbayes.EvalPoissonPmf(k, lam)\n",
    "            return like\n",
    "\n",
    "Each hypothesis is a possible value of $\\lambda$; <span>data</span> is\n",
    "the observed number of goals, <span>k</span>.\n",
    "\n",
    "With the likelihood function in place, we can make a suite for each team\n",
    "and update them with the scores from the first four games.\n",
    "\n",
    "        suite1 = Hockey('bruins')\n",
    "        suite1.UpdateSet([0, 2, 8, 4])\n",
    "         \n",
    "        suite2 = Hockey('canucks')\n",
    "        suite2.UpdateSet([1, 3, 1, 0])\n",
    "\n",
    "Figure [fig.hockey1] shows the resulting posterior distributions for\n",
    "<span>lam</span>. Based on the first four games, the most likely values\n",
    "for <span>lam</span> are 2.6 for the Canucks and 2.9 for the Bruins.\n",
    "\n",
    "The distribution of goals\n",
    "-------------------------\n",
    "\n",
    "![Distribution of goals in a single game.](figs/hockey2.pdf)\n",
    "\n",
    "[fig.hockey2]\n",
    "\n",
    "To compute the probability that each team wins the next game, we need to\n",
    "compute the distribution of goals for each team.\n",
    "\n",
    "If we knew the value of <span>lam</span> exactly, we could use the\n",
    "Poisson distribution again. `thinkbayes` provides a method that computes\n",
    "a truncated approximation of a Poisson distribution:\n",
    "\n",
    "    def MakePoissonPmf(lam, high):\n",
    "        pmf = Pmf()\n",
    "        for k in xrange(0, high+1):\n",
    "            p = EvalPoissonPmf(k, lam)\n",
    "            pmf.Set(k, p)\n",
    "        pmf.Normalize()\n",
    "        return pmf\n",
    "\n",
    "The range of values in the computed Pmf is from 0 to <span>high</span>.\n",
    "So if the value of <span>lam</span> were exactly 3.4, we would compute:\n",
    "\n",
    "    lam = 3.4\n",
    "    goal_dist = thinkbayes.MakePoissonPmf(lam, 10)\n",
    "\n",
    "I chose the upper bound, 10, because the probability of scoring more\n",
    "than 10 goals in a game is quite low.\n",
    "\n",
    "That’s simple enough so far; the problem is that we don’t know the value\n",
    "of <span>lam</span> exactly. Instead, we have a distribution of possible\n",
    "values for <span>lam</span>.\n",
    "\n",
    "For each value of <span>lam</span>, the distribution of goals is\n",
    "Poisson. So the overall distribution of goals is a mixture of these\n",
    "Poisson distributions, weighted according to the probabilities in the\n",
    "distribution of <span>lam</span>.\n",
    "\n",
    "Given the posterior distribution of <span>lam</span>, here’s the code\n",
    "that makes the distribution of goals:\n",
    "\n",
    "    def MakeGoalPmf(suite):\n",
    "        metapmf = thinkbayes.Pmf()\n",
    "\n",
    "        for lam, prob in suite.Items():\n",
    "            pmf = thinkbayes.MakePoissonPmf(lam, 10)\n",
    "            metapmf.Set(pmf, prob)\n",
    "\n",
    "        mix = thinkbayes.MakeMixture(metapmf)\n",
    "        return mix\n",
    "\n",
    "For each value of <span>lam</span> we make a Poisson Pmf and add it to\n",
    "the meta-Pmf. I call it a meta-Pmf because it is a Pmf that contains\n",
    "Pmfs as its values.\n",
    "\n",
    "Then we use `MakeMixture` to compute the mixture (we saw\n",
    "<span>MakeMixture</span> in Section [mixture]).\n",
    "\n",
    "Figure [fig.hockey2] shows the resulting distribution of goals for the\n",
    "Bruins and Canucks. The Bruins are less likely to score 3 goals or fewer\n",
    "in the next game, and more likely to score 4 or more.\n",
    "\n",
    "The probability of winning\n",
    "--------------------------\n",
    "\n",
    "![Distribution of time between goals.](figs/hockey3.pdf)\n",
    "\n",
    "[fig.hockey3]\n",
    "\n",
    "To get the probability of winning, first we compute the distribution of\n",
    "the goal differential:\n",
    "\n",
    "        goal_dist1 = MakeGoalPmf(suite1)\n",
    "        goal_dist2 = MakeGoalPmf(suite2)\n",
    "        diff = goal_dist1 - goal_dist2\n",
    "\n",
    "The subtraction operator invokes `Pmf.__sub__`, which enumerates pairs\n",
    "of values and computes the difference. Subtracting two distributions is\n",
    "almost the same as adding, which we saw in Section [addends].\n",
    "\n",
    "If the goal differential is positive, the Bruins win; if negative, the\n",
    "Canucks win; if 0, it’s a tie:\n",
    "\n",
    "        p_win = diff.ProbGreater(0)\n",
    "        p_loss = diff.ProbLess(0)\n",
    "        p_tie = diff.Prob(0)\n",
    "\n",
    "With the distributions from the previous section, `p_win` is 46%,\n",
    "`p_loss` is 37%, and `p_tie` is 17%.\n",
    "\n",
    "In the event of a tie at the end of “regulation play,” the teams play\n",
    "overtime periods until one team scores. Since the game ends immediately\n",
    "when the first goal is scored, this overtime format is known as “sudden\n",
    "death.”\n",
    "\n",
    "Sudden death\n",
    "------------\n",
    "\n",
    "To compute the probability of winning in a sudden death overtime, the\n",
    "important statistic is not goals per game, but time until the first\n",
    "goal. The assumption that goal-scoring is a Poisson process implies that\n",
    "the time between goals is exponentially distributed.\n",
    "\n",
    "Given <span>lam</span>, we can compute the time between goals like this:\n",
    "\n",
    "    lam = 3.4\n",
    "    time_dist = thinkbayes.MakeExponentialPmf(lam, high=2, n=101)\n",
    "\n",
    "<span>high</span> is the upper bound of the distribution. In this case I\n",
    "chose 2, because the probability of going more than two games without\n",
    "scoring is small. <span>n</span> is the number of values in the Pmf.\n",
    "\n",
    "If we know <span>lam</span> exactly, that’s all there is to it. But we\n",
    "don’t; instead we have a posterior distribution of possible values. So\n",
    "as we did with the distribution of goals, we make a meta-Pmf and compute\n",
    "a mixture of Pmfs.\n",
    "\n",
    "    def MakeGoalTimePmf(suite):\n",
    "        metapmf = thinkbayes.Pmf()\n",
    "\n",
    "        for lam, prob in suite.Items():\n",
    "            pmf = thinkbayes.MakeExponentialPmf(lam, high=2, n=2001)\n",
    "            metapmf.Set(pmf, prob)\n",
    "\n",
    "        mix = thinkbayes.MakeMixture(metapmf)\n",
    "        return mix\n",
    "\n",
    "Figure [fig.hockey3] shows the resulting distributions. For time values\n",
    "less than one period (one third of a game), the Bruins are more likely\n",
    "to score. The time until the Canucks score is more likely to be longer.\n",
    "\n",
    "I set the number of values, <span>n</span>, fairly high in order to\n",
    "minimize the number of ties, since it is not possible for both teams to\n",
    "score simultaneously.\n",
    "\n",
    "Now we compute the probability that the Bruins score first:\n",
    "\n",
    "        time_dist1 = MakeGoalTimePmf(suite1)\n",
    "        time_dist2 = MakeGoalTimePmf(suite2)\n",
    "        p_overtime = thinkbayes.PmfProbLess(time_dist1, time_dist2)\n",
    "\n",
    "For the Bruins, the probability of winning in overtime is 52%.\n",
    "\n",
    "Finally, the total probability of winning is the chance of winning at\n",
    "the end of regulation play plus the probability of winning in overtime.\n",
    "\n",
    "        p_tie = diff.Prob(0)\n",
    "        p_overtime = thinkbayes.PmfProbLess(time_dist1, time_dist2)\n",
    "\n",
    "        p_win = diff.ProbGreater(0) + p_tie * p_overtime\n",
    "\n",
    "For the Bruins, the overall chance of winning the next game is 55%.\n",
    "\n",
    "To win the series, the Bruins can either win the next two games or split\n",
    "the next two and win the third. Again, we can compute the total\n",
    "probability:\n",
    "\n",
    "        # win the next two\n",
    "        p_series = p_win**2\n",
    "\n",
    "        # split the next two, win the third\n",
    "        p_series += 2 * p_win * (1-p_win) * p_win\n",
    "\n",
    "The Bruins chance of winning the series is 57%. And in 2011, they did.\n",
    "\n",
    "Discussion\n",
    "----------\n",
    "\n",
    "As always, the analysis in this chapter is based on modeling decisions,\n",
    "and modeling is almost always an iterative process. In general, you want\n",
    "to start with something simple that yields an approximate answer,\n",
    "identify likely sources of error, and look for opportunities for\n",
    "improvement.\n",
    "\n",
    "In this example, I would consider these options:\n",
    "\n",
    "-   I chose a prior based on the average goals per game for each team.\n",
    "    But this statistic is averaged across all opponents. Against a\n",
    "    particular opponent, we might expect more variability. For example,\n",
    "    if the team with the best offense plays the team with the worst\n",
    "    defense, the expected goals per game might be several standard\n",
    "    deviations above the mean.\n",
    "\n",
    "-   For data I used only the first four games of the championship\n",
    "    series. If the same teams played each other during the regular\n",
    "    season, I could use the results from those games as well. One\n",
    "    complication is that the composition of teams changes during the\n",
    "    season due to trades and injuries. So it might be best to give more\n",
    "    weight to recent games.\n",
    "\n",
    "-   To take advantage of all available information, we could use results\n",
    "    from all regular season games to estimate each team’s goal scoring\n",
    "    rate, possibly adjusted by estimating an additional factor for each\n",
    "    pairwise match-up. This approach would be more complicated, but it\n",
    "    is still feasible.\n",
    "\n",
    "For the first option, we could use the results from the regular season\n",
    "to estimate the variability across all pairwise match-ups. Thanks to\n",
    "Dirk Hoag at <http://forechecker.blogspot.com/>, I was able to get the\n",
    "number of goals scored during regulation play (not overtime) for each\n",
    "game in the regular season.\n",
    "\n",
    "Teams in different conferences only play each other one or two times in\n",
    "the regular season, so I focused on pairs that played each other 4–6\n",
    "times. For each pair, I computed the average goals per game, which is an\n",
    "estimate of $\\lambda$, then plotted the distribution of these estimates.\n",
    "\n",
    "The mean of these estimates is 2.8, again, but the standard deviation is\n",
    "0.85, substantially higher than what we got computing one estimate for\n",
    "each team.\n",
    "\n",
    "If we run the analysis again with the higher-variance prior, the\n",
    "probability that the Bruins win the series is 80%, substantially higher\n",
    "than the result with the low-variance prior, 57%.\n",
    "\n",
    "So it turns out that the results are sensitive to the prior, which makes\n",
    "sense considering how little data we have to work with. Based on the\n",
    "difference between the low-variance model and the high-variable model,\n",
    "it seems worthwhile to put some effort into getting the prior right.\n",
    "\n",
    "The code and data for this chapter are available from\n",
    "<http://thinkbayes.com/hockey.py> and\n",
    "<http://thinkbayes.com/hockey_data.csv>. For more information see\n",
    "Section [download].\n",
    "\n",
    "Exercises\n",
    "---------\n",
    "\n",
    "If buses arrive at a bus stop every 20 minutes, and you arrive at the\n",
    "bus stop at a random time, your wait time until the bus arrives is\n",
    "uniformly distributed from 0 to 20 minutes.\n",
    "\n",
    "But in reality, there is variability in the time between buses. Suppose\n",
    "you are waiting for a bus, and you know the historical distribution of\n",
    "time between buses. Compute your distribution of wait times.\n",
    "\n",
    "Hint: Suppose that the time between buses is either 5 or 10 minutes with\n",
    "equal probability. What is the probability that you arrive during one of\n",
    "the 10 minute intervals?\n",
    "\n",
    "I solve a version of this problem in the next chapter.\n",
    "\n",
    "Suppose that passengers arriving at the bus stop are well-modeled by a\n",
    "Poisson process with parameter $\\lambda$. If you arrive at the stop and\n",
    "find 3 people waiting, what is your posterior distribution for the time\n",
    "since the last bus arrived.\n",
    "\n",
    "I solve a version of this problem in the next chapter.\n",
    "\n",
    "Suppose that you are an ecologist sampling the insect population in a\n",
    "new environment. You deploy 100 traps in a test area and come back the\n",
    "next day to check on them. You find that 37 traps have been triggered,\n",
    "trapping an insect inside. Once a trap triggers, it cannot trap another\n",
    "insect until it has been reset.\n",
    "\n",
    "If you reset the traps and come back in two days, how many traps do you\n",
    "expect to find triggered? Compute a posterior predictive distribution\n",
    "for the number of traps.\n",
    "\n",
    "Suppose you are the manager of an apartment building with 100 light\n",
    "bulbs in common areas. It is your responsibility to replace light bulbs\n",
    "when they break.\n",
    "\n",
    "On January 1, all 100 bulbs are working. When you inspect them on\n",
    "February 1, you find 3 light bulbs out. If you come back on April 1, how\n",
    "many light bulbs do you expect to find broken?\n",
    "\n",
    "In the previous exercise, you could reasonably assume that an event is\n",
    "equally likely at any time. For light bulbs, the likelihood of failure\n",
    "depends on the age of the bulb. Specifically, old bulbs have an\n",
    "increasing failure rate due to evaporation of the filament.\n",
    "\n",
    "This problem is more open-ended than some; you will have to make\n",
    "modeling decisions. You might want to read about the Weibull\n",
    "distribution (<http://en.wikipedia.org/wiki/Weibull_distribution>). Or\n",
    "you might want to look around for information about light bulb survival\n",
    "curves.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
