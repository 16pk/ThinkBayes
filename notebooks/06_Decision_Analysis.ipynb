{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Decision Analysis {#decisionanalysis}\n",
    "=================\n",
    "\n",
    "The <span>*Price is Right*</span> problem\n",
    "-----------------------------------------\n",
    "\n",
    "On November 1, 2007, contestants named Letia and Nathaniel appeared on\n",
    "<span>*The Price is Right*</span>, an American game show. They competed\n",
    "in a game called <span>*The Showcase*</span>, where the objective is to\n",
    "guess the price of a showcase of prizes. The contestant who comes\n",
    "closest to the actual price of the showcase, without going over, wins\n",
    "the prizes.\n",
    "\n",
    "Nathaniel went first. His showcase included a dishwasher, a wine\n",
    "cabinet, a laptop computer, and a car. He bid \\$26,000.\n",
    "\n",
    "Letia’s showcase included a pinball machine, a video arcade game, a pool\n",
    "table, and a cruise of the Bahamas. She bid \\$21,500.\n",
    "\n",
    "The actual price of Nathaniel’s showcase was \\$25,347. His bid was too\n",
    "high, so he lost.\n",
    "\n",
    "The actual price of Letia’s showcase was \\$21,578. She was only off by\n",
    "\\$78, so she won her showcase and, because her bid was off by less than\n",
    "\\$250, she also won Nathaniel’s showcase.\n",
    "\n",
    "For a Bayesian thinker, this scenario suggests several questions:\n",
    "\n",
    "1.  Before seeing the prizes, what prior beliefs should the contestant\n",
    "    have about the price of the showcase?\n",
    "\n",
    "2.  After seeing the prizes, how should the contestant update those\n",
    "    beliefs?\n",
    "\n",
    "3.  Based on the posterior distribution, what should the contestant bid?\n",
    "\n",
    "The third question demonstrates a common use of Bayesian analysis:\n",
    "decision analysis. Given a posterior distribution, we can choose the bid\n",
    "that maximizes the contestant’s expected return.\n",
    "\n",
    "This problem is inspired by an example in Cameron Davidson-Pilon’s book,\n",
    "<span>*Bayesian Methods for Hackers*</span>. The code I wrote for this\n",
    "chapter is available from <http://thinkbayes.com/price.py>; it reads\n",
    "data files you can download from\n",
    "<http://thinkbayes.com/showcases.2011.csv> and\n",
    "<http://thinkbayes.com/showcases.2012.csv>. For more information see\n",
    "Section [download].\n",
    "\n",
    "The prior\n",
    "---------\n",
    "\n",
    "![Distribution of prices for showcases on <span>*The Price is\n",
    "Right*</span>, 2011-12.](figs/price1.pdf)\n",
    "\n",
    "[fig.price1]\n",
    "\n",
    "To choose a prior distribution of prices, we can take advantage of data\n",
    "from previous episodes. Fortunately, fans of the show keep detailed\n",
    "records. When I corresponded with Mr. Davidson-Pilon about his book, he\n",
    "sent me data collected by Steve Gee at <http://tpirsummaries.8m.com>. It\n",
    "includes the price of each showcase from the 2011 and 2012 seasons and\n",
    "the bids offered by the contestants.\n",
    "\n",
    "Figure [fig.price1] shows the distribution of prices for these\n",
    "showcases. The most common value for both showcases is around \\$28,000,\n",
    "but the first showcase has a second mode near \\$50,000, and the second\n",
    "showcase is occasionally worth more than \\$70,000.\n",
    "\n",
    "These distributions are based on actual data, but they have been\n",
    "smoothed by Gaussian kernel density estimation (KDE). Before we go on, I\n",
    "want to take a detour to talk about probability density functions and\n",
    "KDE.\n",
    "\n",
    "Probability density functions\n",
    "-----------------------------\n",
    "\n",
    "So far we have been working with probability mass functions, or PMFs. A\n",
    "PMF is a map from each possible value to its probability. In my\n",
    "implementation, a Pmf object provides a method named <span>Prob</span>\n",
    "that takes a value and returns a probability, also known as a\n",
    "<span>**probability mass**</span>.\n",
    "\n",
    "A <span>**probability density function**</span>, or PDF, is the\n",
    "continuous version of a PMF, where the possible values make up a\n",
    "continuous range rather than a discrete set.\n",
    "\n",
    "In mathematical notation, PDFs are usually written as functions; for\n",
    "example, here is the PDF of a Gaussian distribution with mean 0 and\n",
    "standard deviation 1: $$f(x) = \\frac{1}{\\sqrt{2 \\pi}} \\exp(-x^2/2)$$ For\n",
    "a given value of $x$, this function computes a probability density. A\n",
    "density is similar to a probability mass in the sense that a higher\n",
    "density indicates that a value is more likely.\n",
    "\n",
    "But a density is not a probability. A density can be 0 or any positive\n",
    "value; it is not bounded, like a probability, between 0 and 1.\n",
    "\n",
    "If you integrate a density over a continuous range, the result is a\n",
    "probability. But for the applications in this book we seldom have to do\n",
    "that.\n",
    "\n",
    "Instead we primarily use probability densities as part of a likelihood\n",
    "function. We will see an example soon.\n",
    "\n",
    "Representing PDFs\n",
    "-----------------\n",
    "\n",
    "To represent PDFs in Python, <span>thinkbayes.py</span> provides a class\n",
    "named <span>Pdf</span>. <span>Pdf</span> is an <span>**abstract\n",
    "type**</span>, which means that it defines the interface a Pdf is\n",
    "supposed to have, but does not provide a complete implementation. The\n",
    "<span>Pdf</span> interface includes two methods, <span>Density</span>\n",
    "and <span>MakePmf</span>:\n",
    "\n",
    "    class Pdf(object):\n",
    "\n",
    "        def Density(self, x):\n",
    "            raise UnimplementedMethodException()\n",
    "\n",
    "        def MakePmf(self, xs):\n",
    "            pmf = Pmf()\n",
    "            for x in xs:\n",
    "                pmf.Set(x, self.Density(x))\n",
    "            pmf.Normalize()\n",
    "            return pmf\n",
    "\n",
    "<span>Density</span> takes a value, <span>x</span>, and returns the\n",
    "corresponding density. <span>MakePmf</span> makes a discrete\n",
    "approximation to the PDF.\n",
    "\n",
    "<span>Pdf</span> provides an implementation of <span>MakePmf</span>, but\n",
    "not <span>Density</span>, which has to be provided by a child class.\n",
    "\n",
    "A <span>**concrete type**</span> is a child class that extends an\n",
    "abstract type and provides an implementation of the missing methods. For\n",
    "example, <span>GaussianPdf</span> extends <span>Pdf</span> and provides\n",
    "<span>Density</span>:\n",
    "\n",
    "    class GaussianPdf(Pdf):\n",
    "\n",
    "        def __init__(self, mu, sigma):\n",
    "            self.mu = mu\n",
    "            self.sigma = sigma\n",
    "            \n",
    "        def Density(self, x):\n",
    "            return scipy.stats.norm.pdf(x, self.mu, self.sigma)\n",
    "\n",
    "`__init__` takes <span>mu</span> and <span>sigma</span>, which are the\n",
    "mean and standard deviation of the distribution, and stores them as\n",
    "attributes.\n",
    "\n",
    "<span>Density</span> uses a function from <span>scipy.stats</span> to\n",
    "evaluate the Gaussian PDF. The function is called <span>norm.pdf</span>\n",
    "because the Gaussian distribution is also called the “normal”\n",
    "distribution.\n",
    "\n",
    "The Gaussian PDF is defined by a simple mathematical function, so it is\n",
    "easy to evaluate. And it is useful because many quantities in the real\n",
    "world have distributions that are approximately Gaussian.\n",
    "\n",
    "But with real data, there is no guarantee that the distribution is\n",
    "Gaussian or any other simple mathematical function. In that case we can\n",
    "use a sample to estimate the PDF of the whole population.\n",
    "\n",
    "For example, in <span>*The Price Is Right*</span> data, we have 313\n",
    "prices for the first showcase. We can think of these values as a sample\n",
    "from the population of all possible showcase prices.\n",
    "\n",
    "This sample includes the following values (in order):\n",
    "$$28800, 28868, 28941, 28957, 28958$$ In the sample, no values appear\n",
    "between 28801 and 28867, but there is no reason to think that these\n",
    "values are impossible. Based on our background information, we expect\n",
    "all values in this range to be equally likely. In other words, we expect\n",
    "the PDF to be fairly smooth.\n",
    "\n",
    "Kernel density estimation (KDE) is an algorithm that takes a sample and\n",
    "finds an appropriately smooth PDF that fits the data. You can read\n",
    "details at <http://en.wikipedia.org/wiki/Kernel_density_estimation>.\n",
    "\n",
    "<span>scipy</span> provides an implementation of KDE and\n",
    "<span>thinkbayes</span> provides a class called\n",
    "<span>EstimatedPdf</span> that uses it:\n",
    "\n",
    "    class EstimatedPdf(Pdf):\n",
    "\n",
    "        def __init__(self, sample):\n",
    "            self.kde = scipy.stats.gaussian_kde(sample)\n",
    "\n",
    "        def Density(self, x):\n",
    "            return self.kde.evaluate(x)\n",
    "\n",
    "`__init__` takes a sample and computes a kernel density estimate. The\n",
    "result is a `gaussian_kde` object that provides an <span>evaluate</span>\n",
    "method.\n",
    "\n",
    "<span>Density</span> takes a value, calls `gaussian_kde.evaluate`, and\n",
    "returns the resulting density.\n",
    "\n",
    "Finally, here’s an outline of the code I used to generate\n",
    "Figure [fig.price1]:\n",
    "\n",
    "        prices = ReadData()\n",
    "        pdf = thinkbayes.EstimatedPdf(prices)\n",
    "\n",
    "        low, high = 0, 75000\n",
    "        n = 101\n",
    "        xs = numpy.linspace(low, high, n) \n",
    "        pmf = pdf.MakePmf(xs)\n",
    "\n",
    "<span>pdf</span> is a <span>Pdf</span> object, estimated by KDE.\n",
    "<span>pmf</span> is a Pmf object that approximates the Pdf by evaluating\n",
    "the density at a sequence of equally spaced values.\n",
    "\n",
    "<span>linspace</span> stands for “linear space.” It takes a range,\n",
    "<span>low</span> and <span>high</span>, and the number of points,\n",
    "<span>n</span>, and returns a new <span>numpy</span> array with\n",
    "<span>n</span> elements equally spaced between <span>low</span> and\n",
    "<span>high</span>, including both.\n",
    "\n",
    "And now back to <span>*The Price is Right*</span>.\n",
    "\n",
    "Modeling the contestants\n",
    "------------------------\n",
    "\n",
    "![Cumulative distribution (CDF) of the difference between the\n",
    "contestant’s bid and the actual price.](figs/price2.pdf)\n",
    "\n",
    "[fig.price2]\n",
    "\n",
    "The PDFs in Figure [fig.price1] estimate the distribution of possible\n",
    "prices. If you were a contestant on the show, you could use this\n",
    "distribution to quantify your prior belief about the price of each\n",
    "showcase (before you see the prizes).\n",
    "\n",
    "To update these priors, we have to answer these questions:\n",
    "\n",
    "1.  What data should we consider and how should we quantify it?\n",
    "\n",
    "2.  Can we compute a likelihood function; that is, for each hypothetical\n",
    "    value of <span>price</span>, can we compute the conditional\n",
    "    likelihood of the data?\n",
    "\n",
    "To answer these questions, I am going to model the contestant as a\n",
    "price-guessing instrument with known error characteristics. In other\n",
    "words, when the contestant sees the prizes, he or she guesses the price\n",
    "of each prize—ideally without taking into consideration the fact that\n",
    "the prize is part of a showcase—and adds up the prices. Let’s call this\n",
    "total <span>guess</span>.\n",
    "\n",
    "Under this model, the question we have to answer is, “If the actual\n",
    "price is <span>price</span>, what is the likelihood that the\n",
    "contestant’s estimate would be <span>guess</span>?”\n",
    "\n",
    "Or if we define\n",
    "\n",
    "        error = price - guess\n",
    "\n",
    "then we could ask, “What is the likelihood that the contestant’s\n",
    "estimate is off by <span>error</span>?”\n",
    "\n",
    "To answer this question, we can use the historical data again.\n",
    "Figure [fig.price2] shows the cumulative distribution of\n",
    "<span>diff</span>, the difference between the contestant’s bid and the\n",
    "actual price of the showcase.\n",
    "\n",
    "The definition of diff is\n",
    "\n",
    "        diff = price - bid\n",
    "\n",
    "When <span>diff</span> is negative, the bid is too high. As an aside, we\n",
    "can use this distribution to compute the probability that the\n",
    "contestants overbid: the first contestant overbids 25% of the time; the\n",
    "second contestant overbids 29% of the time.\n",
    "\n",
    "We can also see that the bids are biased; that is, they are more likely\n",
    "to be too low than too high. And that makes sense, given the rules of\n",
    "the game.\n",
    "\n",
    "Finally, we can use this distribution to estimate the reliability of the\n",
    "contestants’ guesses. This step is a little tricky because we don’t\n",
    "actually know the contestant’s guesses; we only know what they bid.\n",
    "\n",
    "So we’ll have to make some assumptions. Specifically, I assume that the\n",
    "distribution of <span>error</span> is Gaussian with mean 0 and the same\n",
    "variance as <span>diff</span>.\n",
    "\n",
    "The <span>Player</span> class implements this model:\n",
    "\n",
    "    class Player(object):\n",
    "\n",
    "        def __init__(self, prices, bids, diffs):\n",
    "            self.pdf_price = thinkbayes.EstimatedPdf(prices)\n",
    "            self.cdf_diff = thinkbayes.MakeCdfFromList(diffs)\n",
    "\n",
    "            mu = 0\n",
    "            sigma = numpy.std(diffs)\n",
    "            self.pdf_error = thinkbayes.GaussianPdf(mu, sigma)\n",
    "\n",
    "<span>prices</span> is a sequence of showcase prices, <span>bids</span>\n",
    "is a sequence of bids, and <span>diffs</span> is a sequence of diffs,\n",
    "where again <span>diff = price - bid</span>.\n",
    "\n",
    "`pdf_price` is the smoothed PDF of prices, estimated by KDE. `cdf_diff`\n",
    "is the cumulative distribution of <span>diff</span>, which we saw in\n",
    "Figure [fig.price2]. And `pdf_error` is the PDF that characterizes the\n",
    "distribution of errors; where <span>error = price - guess</span>.\n",
    "\n",
    "Again, we use the variance of <span>diff</span> to estimate the variance\n",
    "of <span>error</span>. This estimate is not perfect because contestants’\n",
    "bids are sometimes strategic; for example, if Player 2 thinks that\n",
    "Player 1 has overbid, Player 2 might make a very low bid. In that case\n",
    "<span>diff</span> does not reflect <span>error</span>. If this happens a\n",
    "lot, the observed variance in <span>diff</span> might overestimate the\n",
    "variance in <span>error</span>. Nevertheless, I think it is a reasonable\n",
    "modeling decision.\n",
    "\n",
    "As an alternative, someone preparing to appear on the show could\n",
    "estimate their own distribution of <span>error</span> by watching\n",
    "previous shows and recording their guesses and the actual prices.\n",
    "\n",
    "Likelihood\n",
    "----------\n",
    "\n",
    "Now we are ready to write the likelihood function. As usual, I define a\n",
    "new class that extends <span>thinkbayes.Suite</span>:\n",
    "\n",
    "    class Price(thinkbayes.Suite):\n",
    "\n",
    "        def __init__(self, pmf, player):\n",
    "            thinkbayes.Suite.__init__(self, pmf)\n",
    "            self.player = player\n",
    "\n",
    "<span>pmf</span> represents the prior distribution and\n",
    "<span>player</span> is a Player object as described in the previous\n",
    "section. Here’s <span>Likelihood</span>:\n",
    "\n",
    "        def Likelihood(self, data, hypo):\n",
    "            price = hypo\n",
    "            guess = data\n",
    "\n",
    "            error = price - guess\n",
    "            like = self.player.ErrorDensity(error)\n",
    "\n",
    "            return like\n",
    "\n",
    "<span>hypo</span> is the hypothetical price of the showcase.\n",
    "<span>data</span> is the contestant’s best guess at the price.\n",
    "<span>error</span> is the difference, and <span>like</span> is the\n",
    "likelihood of the data, given the hypothesis.\n",
    "\n",
    "<span>ErrorDensity</span> is defined in <span>Player</span>:\n",
    "\n",
    "    # class Player:\n",
    "\n",
    "        def ErrorDensity(self, error):\n",
    "            return self.pdf_error.Density(error)\n",
    "\n",
    "<span>ErrorDensity</span> works by evaluating `pdf_error` at the given\n",
    "value of <span>error</span>. The result is a probability density, so it\n",
    "is not really a probability. But remember that <span>Likelihood</span>\n",
    "doesn’t need to compute a probability; it only has to compute something\n",
    "<span>*proportional*</span> to a probability. As long as the constant of\n",
    "proportionality is the same for all likelihoods, it gets canceled out\n",
    "when we normalize the posterior distribution.\n",
    "\n",
    "And therefore, a probability density is a perfectly good likelihood.\n",
    "\n",
    "Update\n",
    "------\n",
    "\n",
    "![Prior and posterior distributions for Player 1, based on a best guess\n",
    "of \\$20,000.](figs/price3.pdf)\n",
    "\n",
    "[fig.price3]\n",
    "\n",
    "<span>Player</span> provides a method that takes the contestant’s guess\n",
    "and computes the posterior distribution:\n",
    "\n",
    "    # class Player\n",
    "\n",
    "        def MakeBeliefs(self, guess):\n",
    "            pmf = self.PmfPrice()\n",
    "            self.prior = Price(pmf, self)\n",
    "            self.posterior = self.prior.Copy()\n",
    "            self.posterior.Update(guess)\n",
    "\n",
    "<span>PmfPrice</span> generates a discrete approximation to the PDF of\n",
    "price, which we use to construct the prior.\n",
    "\n",
    "<span>PmfPrice</span> uses <span>MakePmf</span>, which evaluates\n",
    "`pdf_price` at a sequence of values:\n",
    "\n",
    "    # class Player\n",
    "\n",
    "        n = 101\n",
    "        price_xs = numpy.linspace(0, 75000, n)\n",
    "\n",
    "        def PmfPrice(self):\n",
    "            return self.pdf_price.MakePmf(self.price_xs)\n",
    "\n",
    "To construct the posterior, we make a copy of the prior and then invoke\n",
    "<span>Update</span>, which invokes <span>Likelihood</span> for each\n",
    "hypothesis, multiplies the priors by the likelihoods, and renormalizes.\n",
    "\n",
    "So let’s get back to the original scenario. Suppose you are Player 1 and\n",
    "when you see your showcase, your best guess is that the total price of\n",
    "the prizes is \\$20,000.\n",
    "\n",
    "Figure [fig.price3] shows prior and posterior beliefs about the actual\n",
    "price. The posterior is shifted to the left because your guess is on the\n",
    "low end of the prior range.\n",
    "\n",
    "On one level, this result makes sense. The most likely value in the\n",
    "prior is \\$27,750, your best guess is \\$20,000, and the mean of the\n",
    "posterior is somewhere in between: \\$25,096.\n",
    "\n",
    "On another level, you might find this result bizarre, because it\n",
    "suggests that if you <span>*think*</span> the price is \\$20,000, then\n",
    "you should <span>*believe*</span> the price is \\$24,000.\n",
    "\n",
    "To resolve this apparent paradox, remember that you are combining two\n",
    "sources of information, historical data about past showcases and guesses\n",
    "about the prizes you see.\n",
    "\n",
    "We are treating the historical data as the prior and updating it based\n",
    "on your guesses, but we could equivalently use your guess as a prior and\n",
    "update it based on historical data.\n",
    "\n",
    "If you think of it that way, maybe it is less surprising that the most\n",
    "likely value in the posterior is not your original guess.\n",
    "\n",
    "Optimal bidding\n",
    "---------------\n",
    "\n",
    "Now that we have a posterior distribution, we can use it to compute the\n",
    "optimal bid, which I define as the bid that maximizes expected return\n",
    "(see <http://en.wikipedia.org/wiki/Expected_return>).\n",
    "\n",
    "I’m going to present the methods in this section top-down, which means I\n",
    "will show you how they are used before I show you how they work. If you\n",
    "see an unfamiliar method, don’t worry; the definition will be along\n",
    "shortly.\n",
    "\n",
    "To compute optimal bids, I wrote a class called\n",
    "<span>GainCalculator</span>:\n",
    "\n",
    "    class GainCalculator(object):\n",
    "\n",
    "        def __init__(self, player, opponent):\n",
    "            self.player = player\n",
    "            self.opponent = opponent\n",
    "\n",
    "<span>player</span> and <span>opponent</span> are <span>Player</span>\n",
    "objects.\n",
    "\n",
    "<span>GainCalculator</span> provides <span>ExpectedGains</span>, which\n",
    "computes a sequence of bids and the expected gain for each bid:\n",
    "\n",
    "        def ExpectedGains(self, low=0, high=75000, n=101):\n",
    "            bids = numpy.linspace(low, high, n)\n",
    "\n",
    "            gains = [self.ExpectedGain(bid) for bid in bids]\n",
    "\n",
    "            return bids, gains\n",
    "\n",
    "<span>low</span> and <span>high</span> specify the range of possible\n",
    "bids; <span>n</span> is the number of bids to try.\n",
    "\n",
    "<span>ExpectedGains</span> calls <span>ExpectedGain</span>, which\n",
    "computes expected gain for a given bid:\n",
    "\n",
    "        def ExpectedGain(self, bid):\n",
    "            suite = self.player.posterior\n",
    "            total = 0\n",
    "            for price, prob in sorted(suite.Items()):\n",
    "                gain = self.Gain(bid, price)\n",
    "                total += prob * gain\n",
    "            return total\n",
    "\n",
    "<span>ExpectedGain</span> loops through the values in the posterior and\n",
    "computes the gain for each bid, given the actual prices of the showcase.\n",
    "It weights each gain with the corresponding probability and returns the\n",
    "total.\n",
    "\n",
    "![Expected gain versus bid in a scenario where Player 1’s best guess is\n",
    "\\$20,000 and Player 2’s best guess is \\$40,000.](figs/price5.pdf)\n",
    "\n",
    "[fig.price5]\n",
    "\n",
    "<span>ExpectedGain</span> invokes <span>Gain</span>, which takes a bid\n",
    "and an actual price and returns the expected gain:\n",
    "\n",
    "        def Gain(self, bid, price):\n",
    "            if bid > price:\n",
    "                return 0\n",
    "\n",
    "            diff = price - bid\n",
    "            prob = self.ProbWin(diff)\n",
    "\n",
    "            if diff <= 250:\n",
    "                return 2 * price * prob\n",
    "            else:\n",
    "                return price * prob\n",
    "\n",
    "If you overbid, you get nothing. Otherwise we compute the difference\n",
    "between your bid and the price, which determines your probability of\n",
    "winning.\n",
    "\n",
    "If <span>diff</span> is less than \\$250, you win both showcases. For\n",
    "simplicity, I assume that both showcases have the same price. Since this\n",
    "outcome is rare, it doesn’t make much difference.\n",
    "\n",
    "Finally, we have to compute the probability of winning based on\n",
    "<span>diff</span>:\n",
    "\n",
    "        def ProbWin(self, diff):\n",
    "            prob = (self.opponent.ProbOverbid() + \n",
    "                    self.opponent.ProbWorseThan(diff))\n",
    "            return prob\n",
    "\n",
    "If your opponent overbids, you win. Otherwise, you have to hope that\n",
    "your opponent is off by more than <span>diff</span>. <span>Player</span>\n",
    "provides methods to compute both probabilities:\n",
    "\n",
    "    # class Player:\n",
    "\n",
    "        def ProbOverbid(self):\n",
    "            return self.cdf_diff.Prob(-1)\n",
    "\n",
    "        def ProbWorseThan(self, diff):\n",
    "            return 1 - self.cdf_diff.Prob(diff)\n",
    "\n",
    "This code might be confusing because the computation is now from the\n",
    "point of view of the opponent, who is computing, “What is the\n",
    "probability that I overbid?” and “What is the probability that my bid is\n",
    "off by more than <span>diff</span>?”\n",
    "\n",
    "Both answers are based on the CDF of <span>diff</span>. If the\n",
    "opponent’s <span>diff</span> is less than or equal to -1, you win. If\n",
    "the opponent’s <span>diff</span> is worse than yours, you win. Otherwise\n",
    "you lose.\n",
    "\n",
    "Finally, here’s the code that computes optimal bids:\n",
    "\n",
    "    # class Player:\n",
    "\n",
    "        def OptimalBid(self, guess, opponent):\n",
    "            self.MakeBeliefs(guess)\n",
    "            calc = GainCalculator(self, opponent)\n",
    "            bids, gains = calc.ExpectedGains()\n",
    "            gain, bid = max(zip(gains, bids))\n",
    "            return bid, gain\n",
    "\n",
    "Given a guess and an opponent, <span>OptimalBid</span> computes the\n",
    "posterior distribution, instantiates a <span>GainCalculator</span>,\n",
    "computes expected gains for a range of bids and returns the optimal bid\n",
    "and expected gain. Whew!\n",
    "\n",
    "Figure [fig.price5] shows the results for both players, based on a\n",
    "scenario where Player 1’s best guess is \\$20,000 and Player 2’s best\n",
    "guess is \\$40,000.\n",
    "\n",
    "For Player 1 the optimal bid is \\$21,000, yielding an expected return of\n",
    "almost \\$16,700. This is a case (which turns out to be unusual) where\n",
    "the optimal bid is actually higher than the contestant’s best guess.\n",
    "\n",
    "For Player 2 the optimal bid is \\$31,500, yielding an expected return of\n",
    "almost \\$19,400. This is the more typical case where the optimal bid is\n",
    "less than the best guess.\n",
    "\n",
    "Discussion\n",
    "----------\n",
    "\n",
    "One of the features of Bayesian estimation is that the result comes in\n",
    "the form of a posterior distribution. Classical estimation usually\n",
    "generates a single point estimate or a confidence interval, which is\n",
    "sufficient if estimation is the last step in the process, but if you\n",
    "want to use an estimate as an input to a subsequent analysis, point\n",
    "estimates and intervals are often not much help.\n",
    "\n",
    "In this example, we use the posterior distribution to compute an optimal\n",
    "bid. The return on a given bid is asymmetric and discontinuous (if you\n",
    "overbid, you lose), so it would be hard to solve this problem\n",
    "analytically. But it is relatively simple to do computationally.\n",
    "\n",
    "Newcomers to Bayesian thinking are often tempted to summarize the\n",
    "posterior distribution by computing the mean or the maximum likelihood\n",
    "estimate. These summaries can be useful, but if that’s all you need,\n",
    "then you probably don’t need Bayesian methods in the first place.\n",
    "\n",
    "Bayesian methods are most useful when you can carry the posterior\n",
    "distribution into the next step of the analysis to perform some kind of\n",
    "decision analysis, as we did in this chapter, or some kind of\n",
    "prediction, as we see in the next chapter.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
